{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFD7DVZ-xKdT"
   },
   "source": [
    "# Text Preprocessing with Vietnamese\n",
    "**Overview:** In this exercise, we will build a text preprocessing program for Vietnamese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOAeiqdrxKdt"
   },
   "source": [
    "Import the necessary libraries. Note that we are using the underthesea library for Vietnamese tokenization. To install it, follow the instructions below. ([link](https://github.com/undertheseanlp/underthesea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3720,
     "status": "ok",
     "timestamp": 1769420099135,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "vCmzazMMZtIl",
    "outputId": "686565a2-cc23-4298-d8cb-3c61ab92c89c"
   },
   "outputs": [],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1769420099162,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "RrFQ_Ht_xKdu"
   },
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import codecs\n",
    "import sys\n",
    "import re\n",
    "from underthesea import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hC27lBQZxKdw"
   },
   "source": [
    "## Question 1: Create a Corpus and Survey the Data\n",
    "\n",
    "The data in this section is partially extracted from the [VNTC](https://github.com/duyvuleo/VNTC) dataset. VNTC is a Vietnamese news dataset covering various topics. In this section, we will only process the science topic from VNTC. We will create a corpus from both the train and test directories. Complete the following program:\n",
    "\n",
    "- Write `sentences_list` to a file named `dataset_name.txt`, with each element as a document on a separate line.\n",
    "- Check how many documents are in the corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Train and Test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 28063,
     "status": "ok",
     "timestamp": 1769420127234,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "NQu_bjVgtZNE",
    "outputId": "d59dae3a-7684-4040-d94b-af7969c735a7"
   },
   "outputs": [],
   "source": [
    "!mkdir -p VNTC_khoahoc\n",
    "\n",
    "train_url = \"https://github.com/duyvuleo/VNTC/raw/master/Data/10Topics/Ver1.1/Train_Full.rar\"\n",
    "test_url = \"https://github.com/duyvuleo/VNTC/raw/master/Data/10Topics/Ver1.1/Test_Full.rar\"\n",
    "!wget {train_url}\n",
    "!wget {test_url}\n",
    "\n",
    "!unrar x Train_Full.rar VNTC_khoahoc/\n",
    "!unrar x Test_Full.rar VNTC_khoahoc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1769420127459,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "GyNKT8wAxKdx",
    "outputId": "c67aecfa-602a-49db-c115-582f4ff020e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels = test labels\n",
      "Number documents in the corpus: 3916\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"VNTC_khoahoc\"\n",
    "\n",
    "path = ['./VNTC_khoahoc/Train_Full/', './VNTC_khoahoc/Test_Full/']\n",
    "\n",
    "if os.listdir(path[0]) == os.listdir(path[1]):\n",
    "    folder_list = [os.listdir(path[0]), os.listdir(path[1])]\n",
    "    print(\"train labels = test labels\")\n",
    "else:\n",
    "    print(\"train labels differ from test labels\")\n",
    "\n",
    "doc_num = 0\n",
    "sentences_list = []\n",
    "meta_data_list = []\n",
    "for i in range(2):\n",
    "    folder_path = path[i] + \"Khoa hoc\"\n",
    "    if os.path.exists(folder_path):\n",
    "      for file_name in glob.glob(os.path.join(folder_path, '*.txt')):\n",
    "          f = codecs.open(file_name, 'br')\n",
    "          file_content = (f.read().decode(\"utf-16\")).replace(\"\\r\\n\", \" \")\n",
    "          sentences_list.append(file_content.strip())\n",
    "          f.close\n",
    "          doc_num += 1\n",
    "\n",
    "#### YOUR CODE HERE ####\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBBGzrVlZtIp"
   },
   "source": [
    "## Question 2: Write Preprocessing Functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KXHcDpuxKd0"
   },
   "source": [
    "### Question 2.1: Write a Function to Clean Text\n",
    "Hint:\n",
    "- The text should only retain the following characters: aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0-9(),!?\\'\\\n",
    "- Then trim the whitespace in the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1769420127504,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "k8hIglDXxKd0"
   },
   "outputs": [],
   "source": [
    "def clean_str(string: str) -> str:\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KfXstqAxKd1"
   },
   "source": [
    "### Question 2.2: Write a Function to Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1769420127564,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "KRwgVjxhxKd1"
   },
   "outputs": [],
   "source": [
    "# make all text lowercase\n",
    "def text_lowercase(string: str) -> str:\n",
    "    #### YOUR CODE HERE ###\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYM_GO_5xKd2"
   },
   "source": [
    "### Question 2.3: Tokenize Words\n",
    "Hint: Use the `word_tokenize()` function imported above with two parameters: `strings` and `format=\"text\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1769420127567,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "pty34NwyxKd2"
   },
   "outputs": [],
   "source": [
    "def tokenize(strings: str) -> str:\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    #### END YOUR CODE #####\n",
    "# help(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gQGmL4gxKd2"
   },
   "source": [
    "### Question 2.4: Remove Stop Words\n",
    "To remove stop words, we use a list of Vietnamese stop words stored in the file `./vietnamese-stopwords.txt`. Complete the following program:\n",
    "- Check each word in the text (`strings`). If a word is not in the stop words list, add it to `doc_words`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1769420127658,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "aqStv2rPxKd3"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt\"\n",
    "raw_data = urlopen(url).read().decode(\"utf-8\")\n",
    "STOPWORDS_SET = set(raw_data.split(\"\\n\"))\n",
    "\n",
    "def remove_stopwords(strings):\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUNOKigIxKd4"
   },
   "source": [
    "## Question 2.5: Build a Preprocessing Function\n",
    "Hint: Call the functions `clean_str`, `text_lowercase`, `tokenize`, and `remove_stopwords` in order, then return the result from the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1769420127663,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "_vd-el91xKd_"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(strings):\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BGOqa1mxKeA"
   },
   "source": [
    "## Question 3: Perform Preprocessing\n",
    "Now, we will read the corpus from the file created in Question 1. After that, we will call the preprocessing function for each document in the corpus.\n",
    "\n",
    "Hint: Call the `text_preprocessing()` function with `doc_content` as the input parameter and save the result in the variable `temp1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109315,
     "status": "ok",
     "timestamp": 1769420236989,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "ii030C-RZtIv",
    "outputId": "454f576c-e346-408f-9794-455be16064a9"
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "clean_docs = []\n",
    "with open(\"VNTC_khoahoc.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pass\n",
    "\n",
    "#### END YOUR CODE #####\n",
    "\n",
    "print(\"\\nlength of clean_docs = \", len(clean_docs))\n",
    "print('clean_docs[0]:\\n' + clean_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFhai6BwxKeB"
   },
   "source": [
    "## Question 4: Save Preprocessed Data\n",
    "Hint: Save the preprocessed data to a file named `dataset_name + '.clean.txt'`, where each document is written on a separate line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1769420252895,
     "user": {
      "displayName": "Quốc Hiệu Nguyễn",
      "userId": "03425075822245856665"
     },
     "user_tz": -420
    },
    "id": "xfHmSiRrxKeB"
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "\n",
    "#### YOUR CODE HERE ####"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
