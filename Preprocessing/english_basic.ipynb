{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1scE5rBNAR2G"
   },
   "source": [
    "# Text Data Preprocessing\n",
    "**Overview:** In this lesson, we will build a text preprocessing pipeline for English text, which includes: data cleaning, converting to lowercase, removing punctuation, tokenization, removing stop words, and stemming. The exercise requires knowledge and programming skills in Python using libraries such as string, re, nltk, and numpy.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G8XZPuMAR2T"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ijK-PShAR2V"
   },
   "outputs": [],
   "source": [
    "import string # used for preprocessing\n",
    "import re # used for preprocessing\n",
    "import nltk # the Natural Language Toolkit, used for preprocessing\n",
    "import numpy as np # used for managing NaNs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords # used for preprocessing\n",
    "from nltk.stem import WordNetLemmatizer # used for preprocessing\n",
    "from nltk import pos_tag\n",
    "from typing import List\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0DQgAkWAR2W"
   },
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "The raw text data that needs preprocessing is in the file \"wiki.txt\". This file contains short documents (docs), with each document on a separate line. In this question, we will explore the following:\n",
    "\n",
    "- The number of docs in the corpus\n",
    "- Observing a few docs from the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsbV9GSEAR2X",
    "outputId": "e5590b0b-38c0-4f34-bd1b-b202ded3338d"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen \n",
    "url = \"https://raw.githubusercontent.com/HatakekkSheeshh/NLP_for_Practice/main/Preprocessing/wiki.txt\"\n",
    "raw_data = urlopen(url).read().decode('utf-8')\n",
    "docs = raw_data.split('\\n')\n",
    "\n",
    "# Number of docs\n",
    "print(f\"Number of docs: {len(docs)}\\n\")\n",
    "\n",
    "# Observing a few docs\n",
    "print(\"Observing a few docs:\")\n",
    "for i in range(10):\n",
    "    print(docs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Building Text Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6I8R30NAR2c"
   },
   "source": [
    "### Question 1.1: Building a Data Cleaning Function\n",
    "\n",
    "**Description:** The function removes digits and keeps only the characters \"A-Za-z(),!?\\'\\`\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80LZzOxCAR2d"
   },
   "outputs": [],
   "source": [
    "# clean text\n",
    "def clean_text(text: str) -> str:\n",
    "    #### YOUR CODE HERE ####\n",
    "    regex = r\"[^A-Za-z(),!?'`]\"\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLyDqwtcAR2d"
   },
   "source": [
    "### Question 1.2: Function to Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5N6q83DAR2e"
   },
   "outputs": [],
   "source": [
    "# make all text lowercase\n",
    "#### YOUR CODE HERE ####\n",
    "def text_lowercase(text: str) -> str:\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vkzajg44AR2e"
   },
   "source": [
    "### Question 1.3: Building a Function to Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLFWvQRLAR2f"
   },
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    #### YOUR CODE HERE ####\n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_ocSyA9AR2f"
   },
   "source": [
    "### Question 1.4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru8lNWuDAR2g"
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    #### YOUR CODE HERE ####  \n",
    "\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9L8rJildAR2g"
   },
   "source": [
    "### Question 1.5: Removing Stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-03fXud4AR2h"
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#### YOUR CODE HERE ####\n",
    "def remove_stopwords(text: List[str]) -> List[str]:\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVXH3PorAR2h"
   },
   "source": [
    "### Question 1.6: Building a Lemmatization Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNb3hemPAR2i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'run', 'go']\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "def lemmatize(text: List[str]) -> List[str]:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "#### END YOUR CODE #####\n",
    "\n",
    "# help(lemmatizer)  # Use this for the detail of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pr3h3J4AR2i"
   },
   "source": [
    "### Question 1.7: Building a Preprocessing Function\n",
    "**Hint:** This function will call the functions written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpM1j8v9AR2i"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text: List[str]) -> List[List[str]]:\n",
    "#### YOUR CODE HERE ####\n",
    "\n",
    "#### END YOUR CODE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQJicZUrAR2j"
   },
   "source": [
    "## Question 2: Preprocessing for Input Text\n",
    "**Overview:** Using the functions above, preprocess the initial text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSWwb3gsAR2j",
    "outputId": "5e0d91f7-f4cb-4998-e890-c38bb064377b"
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
